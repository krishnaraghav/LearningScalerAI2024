{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "69d20e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff058f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('./Kaggle_Dataset/Titanic-Dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38e962b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                   Moran, Mr. James    male   NaN      0   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  \n",
       "5      0            330877   8.4583   NaN        Q  \n",
       "6      0             17463  51.8625   E46        S  \n",
       "7      1            349909  21.0750   NaN        S  \n",
       "8      2            347742  11.1333   NaN        S  \n",
       "9      0            237736  30.0708   NaN        C  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "580eb64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a76d25c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94f242a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value counts for Name:\n",
      "Name\n",
      "Braund, Mr. Owen Harris                     1\n",
      "Boulos, Mr. Hanna                           1\n",
      "Frolicher-Stehli, Mr. Maxmillian            1\n",
      "Gilinski, Mr. Eliezer                       1\n",
      "Murdlin, Mr. Joseph                         1\n",
      "                                           ..\n",
      "Kelly, Miss. Anna Katherine \"Annie Kate\"    1\n",
      "McCoy, Mr. Bernard                          1\n",
      "Johnson, Mr. William Cahoone Jr             1\n",
      "Keane, Miss. Nora A                         1\n",
      "Dooley, Mr. Patrick                         1\n",
      "Name: count, Length: 891, dtype: int64\n",
      "\n",
      "Value counts for Sex:\n",
      "Sex\n",
      "male      577\n",
      "female    314\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Value counts for Ticket:\n",
      "Ticket\n",
      "347082      7\n",
      "CA. 2343    7\n",
      "1601        7\n",
      "3101295     6\n",
      "CA 2144     6\n",
      "           ..\n",
      "9234        1\n",
      "19988       1\n",
      "2693        1\n",
      "PC 17612    1\n",
      "370376      1\n",
      "Name: count, Length: 681, dtype: int64\n",
      "\n",
      "Value counts for Cabin:\n",
      "Cabin\n",
      "B96 B98        4\n",
      "G6             4\n",
      "C23 C25 C27    4\n",
      "C22 C26        3\n",
      "F33            3\n",
      "              ..\n",
      "E34            1\n",
      "C7             1\n",
      "C54            1\n",
      "E36            1\n",
      "C148           1\n",
      "Name: count, Length: 147, dtype: int64\n",
      "\n",
      "Value counts for Embarked:\n",
      "Embarked\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for column in df.select_dtypes(include='object').columns:\n",
    "    print(f\"Value counts for {column}:\\n{df[column].value_counts()}\\n\")\n",
    "    \n",
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44bc455b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "    df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9ed3beaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df['Age']=df['Age'].fillna(df['Age'].mean())\n",
    "print(df['Age'].isnull().sum())  # This should print 0, meaning no missing values left\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62ca09e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          891 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f772f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          891 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        891 non-null    object \n",
      " 11  Embarked     891 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df['Cabin']=df['Cabin'].fillna(df['Cabin'].mode()[0])\n",
    "df['Embarked']=df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6e2a015a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "5            6         0       3   \n",
       "6            7         0       1   \n",
       "7            8         0       3   \n",
       "8            9         1       3   \n",
       "9           10         1       2   \n",
       "\n",
       "                                                Name     Sex        Age  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.000000   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.000000   \n",
       "2                             Heikkinen, Miss. Laina  female  26.000000   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.000000   \n",
       "4                           Allen, Mr. William Henry    male  35.000000   \n",
       "5                                   Moran, Mr. James    male  29.699118   \n",
       "6                            McCarthy, Mr. Timothy J    male  54.000000   \n",
       "7                     Palsson, Master. Gosta Leonard    male   2.000000   \n",
       "8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.000000   \n",
       "9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.000000   \n",
       "\n",
       "   SibSp  Parch            Ticket     Fare    Cabin Embarked  \n",
       "0      1      0         A/5 21171   7.2500  B96 B98        S  \n",
       "1      1      0          PC 17599  71.2833      C85        C  \n",
       "2      0      0  STON/O2. 3101282   7.9250  B96 B98        S  \n",
       "3      1      0            113803  53.1000     C123        S  \n",
       "4      0      0            373450   8.0500  B96 B98        S  \n",
       "5      0      0            330877   8.4583  B96 B98        Q  \n",
       "6      0      0             17463  51.8625      E46        S  \n",
       "7      3      1            349909  21.0750  B96 B98        S  \n",
       "8      0      2            347742  11.1333  B96 B98        S  \n",
       "9      1      0            237736  30.0708  B96 B98        C  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "469e0466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "5            6       3                                   Moran, Mr. James   \n",
       "6            7       1                            McCarthy, Mr. Timothy J   \n",
       "7            8       3                     Palsson, Master. Gosta Leonard   \n",
       "8            9       3  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)   \n",
       "9           10       2                Nasser, Mrs. Nicholas (Adele Achem)   \n",
       "\n",
       "      Sex        Age  SibSp  Parch            Ticket     Fare    Cabin  \\\n",
       "0    male  22.000000      1      0         A/5 21171   7.2500  B96 B98   \n",
       "1  female  38.000000      1      0          PC 17599  71.2833      C85   \n",
       "2  female  26.000000      0      0  STON/O2. 3101282   7.9250  B96 B98   \n",
       "3  female  35.000000      1      0            113803  53.1000     C123   \n",
       "4    male  35.000000      0      0            373450   8.0500  B96 B98   \n",
       "5    male  29.699118      0      0            330877   8.4583  B96 B98   \n",
       "6    male  54.000000      0      0             17463  51.8625      E46   \n",
       "7    male   2.000000      3      1            349909  21.0750  B96 B98   \n",
       "8  female  27.000000      0      2            347742  11.1333  B96 B98   \n",
       "9  female  14.000000      1      0            237736  30.0708  B96 B98   \n",
       "\n",
       "  Embarked  \n",
       "0        S  \n",
       "1        C  \n",
       "2        S  \n",
       "3        S  \n",
       "4        S  \n",
       "5        Q  \n",
       "6        S  \n",
       "7        S  \n",
       "8        S  \n",
       "9        C  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " feature=df.drop(columns=['Survived'])\n",
    "label=df[['Survived']]\n",
    "feature.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d26f7173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived\n",
       "0         0\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         0\n",
       "5         0\n",
       "6         0\n",
       "7         0\n",
       "8         1\n",
       "9         1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " label.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06f27b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(feature.ndim)\n",
    "print(label.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2830b86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass     Sex        Age  SibSp  Parch     Fare Embarked\n",
       "0       3    male  22.000000      1      0   7.2500        S\n",
       "1       1  female  38.000000      1      0  71.2833        C\n",
       "2       3  female  26.000000      0      0   7.9250        S\n",
       "3       1  female  35.000000      1      0  53.1000        S\n",
       "4       3    male  35.000000      0      0   8.0500        S\n",
       "5       3    male  29.699118      0      0   8.4583        Q\n",
       "6       1    male  54.000000      0      0  51.8625        S\n",
       "7       3    male   2.000000      3      1  21.0750        S\n",
       "8       3  female  27.000000      0      2  11.1333        S\n",
       "9       2  female  14.000000      1      0  30.0708        C"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature.head(10)\n",
    "feature.drop(columns=['Name'], inplace=True)\n",
    "feature.drop(columns=['Ticket'],inplace=True)\n",
    "feature.drop(columns=['Cabin'],inplace=True)\n",
    "feature.drop(columns=['PassengerId'],inplace=True)\n",
    "\n",
    "feature.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0c2154b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex        Age  SibSp  Parch     Fare  Embarked\n",
       "0       3    1  22.000000      1      0   7.2500         2\n",
       "1       1    0  38.000000      1      0  71.2833         0\n",
       "2       3    0  26.000000      0      0   7.9250         2\n",
       "3       1    0  35.000000      1      0  53.1000         2\n",
       "4       3    1  35.000000      0      0   8.0500         2\n",
       "5       3    1  29.699118      0      0   8.4583         1\n",
       "6       1    1  54.000000      0      0  51.8625         2\n",
       "7       3    1   2.000000      3      1  21.0750         2\n",
       "8       3    0  27.000000      0      2  11.1333         2\n",
       "9       2    0  14.000000      1      0  30.0708         0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "for column in feature.select_dtypes(include='object').columns:\n",
    "    feature[column] = le.fit_transform(feature[column])\n",
    "    \n",
    "feature.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "532d5771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived\n",
       "0         0\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         0\n",
       "5         0\n",
       "6         0\n",
       "7         0\n",
       "8         1\n",
       "9         1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99eb2127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " feature.ndim\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57877a70",
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test= train_test_split(feature,label,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fbb1a723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train  = scaler.fit_transform(x_train)\n",
    "x_test  = scaler.fit_transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "41f46813",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.values.ravel() # to convert labels to 1d array \n",
    "y_test=y_test.values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "408729b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Using cached tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.70.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\raghav\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.0)\n",
      "Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Using cached tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "Installing collected packages: tensorflow-intel, tensorflow\n",
      "Successfully installed tensorflow-2.18.0 tensorflow-intel-2.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aeb8a96-b152-455c-8427-8482ace1567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7e6b098-0446-426a-a0d4-a7b977116ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw\n",
    "\n",
    "model.add(Dense(units=11,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=11,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(units=4,activation='sigmoid'))\n",
    "\n",
    "model.add(Dense(units=2,activation='sigmoid'))\n",
    "\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "# For a binary classification problem\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b23ad00f-e1f6-4d22-a29d-955efb3107da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=25)\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=3000,\n",
    "          validation_data=(X_test, y_test), verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4f55498a-a3fb-41d8-b883-4634d4fe7b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 76ms/step - loss: 0.6825 - val_loss: 0.6838\n",
      "Epoch 2/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.6767 - val_loss: 0.6810\n",
      "Epoch 3/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.6761 - val_loss: 0.6790\n",
      "Epoch 4/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.6729 - val_loss: 0.6775\n",
      "Epoch 5/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.6657 - val_loss: 0.6758\n",
      "Epoch 6/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.6655 - val_loss: 0.6740\n",
      "Epoch 7/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.6598 - val_loss: 0.6712\n",
      "Epoch 8/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.6507 - val_loss: 0.6674\n",
      "Epoch 9/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.6526 - val_loss: 0.6622\n",
      "Epoch 10/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.6431 - val_loss: 0.6557\n",
      "Epoch 11/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.6506 - val_loss: 0.6483\n",
      "Epoch 12/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.6366 - val_loss: 0.6412\n",
      "Epoch 13/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.6412 - val_loss: 0.6339\n",
      "Epoch 14/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.6246 - val_loss: 0.6264\n",
      "Epoch 15/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.6286 - val_loss: 0.6192\n",
      "Epoch 16/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.6273 - val_loss: 0.6128\n",
      "Epoch 17/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.6176 - val_loss: 0.6075\n",
      "Epoch 18/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.6095 - val_loss: 0.6025\n",
      "Epoch 19/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.6005 - val_loss: 0.5974\n",
      "Epoch 20/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.5900 - val_loss: 0.5927\n",
      "Epoch 21/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.5908 - val_loss: 0.5881\n",
      "Epoch 22/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.5782 - val_loss: 0.5831\n",
      "Epoch 23/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.5798 - val_loss: 0.5789\n",
      "Epoch 24/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.5874 - val_loss: 0.5749\n",
      "Epoch 25/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.5668 - val_loss: 0.5707\n",
      "Epoch 26/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.5822 - val_loss: 0.5663\n",
      "Epoch 27/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.5581 - val_loss: 0.5628\n",
      "Epoch 28/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.5692 - val_loss: 0.5594\n",
      "Epoch 29/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.5622 - val_loss: 0.5556\n",
      "Epoch 30/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.5555 - val_loss: 0.5521\n",
      "Epoch 31/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.5555 - val_loss: 0.5484\n",
      "Epoch 32/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - loss: 0.5708 - val_loss: 0.5449\n",
      "Epoch 33/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - loss: 0.5403 - val_loss: 0.5409\n",
      "Epoch 34/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.5401 - val_loss: 0.5370\n",
      "Epoch 35/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.5300 - val_loss: 0.5343\n",
      "Epoch 36/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.5321 - val_loss: 0.5315\n",
      "Epoch 37/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.5555 - val_loss: 0.5288\n",
      "Epoch 38/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.5363 - val_loss: 0.5255\n",
      "Epoch 39/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.5160 - val_loss: 0.5222\n",
      "Epoch 40/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.5061 - val_loss: 0.5191\n",
      "Epoch 41/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.5278 - val_loss: 0.5164\n",
      "Epoch 42/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - loss: 0.5167 - val_loss: 0.5138\n",
      "Epoch 43/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.5255 - val_loss: 0.5115\n",
      "Epoch 44/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.5133 - val_loss: 0.5075\n",
      "Epoch 45/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.5150 - val_loss: 0.5049\n",
      "Epoch 46/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.5126 - val_loss: 0.5023\n",
      "Epoch 47/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - loss: 0.5207 - val_loss: 0.5007\n",
      "Epoch 48/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.5242 - val_loss: 0.4986\n",
      "Epoch 49/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - loss: 0.5160 - val_loss: 0.4955\n",
      "Epoch 50/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.5138 - val_loss: 0.4937\n",
      "Epoch 51/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.5063 - val_loss: 0.4914\n",
      "Epoch 52/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.5003 - val_loss: 0.4889\n",
      "Epoch 53/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.5339 - val_loss: 0.4868\n",
      "Epoch 54/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.5103 - val_loss: 0.4846\n",
      "Epoch 55/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.4798 - val_loss: 0.4811\n",
      "Epoch 56/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.5127 - val_loss: 0.4794\n",
      "Epoch 57/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.5015 - val_loss: 0.4775\n",
      "Epoch 58/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.5121 - val_loss: 0.4756\n",
      "Epoch 59/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4822 - val_loss: 0.4738\n",
      "Epoch 60/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.4905 - val_loss: 0.4717\n",
      "Epoch 61/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.5029 - val_loss: 0.4706\n",
      "Epoch 62/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4856 - val_loss: 0.4681\n",
      "Epoch 63/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.4870 - val_loss: 0.4675\n",
      "Epoch 64/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4867 - val_loss: 0.4662\n",
      "Epoch 65/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4813 - val_loss: 0.4678\n",
      "Epoch 66/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4492 - val_loss: 0.4689\n",
      "Epoch 67/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.4603 - val_loss: 0.4688\n",
      "Epoch 68/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4827 - val_loss: 0.4658\n",
      "Epoch 69/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4749 - val_loss: 0.4638\n",
      "Epoch 70/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4931 - val_loss: 0.4624\n",
      "Epoch 71/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.4591 - val_loss: 0.4620\n",
      "Epoch 72/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4651 - val_loss: 0.4621\n",
      "Epoch 73/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4879 - val_loss: 0.4608\n",
      "Epoch 74/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4707 - val_loss: 0.4594\n",
      "Epoch 75/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.4560 - val_loss: 0.4578\n",
      "Epoch 76/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.4696 - val_loss: 0.4561\n",
      "Epoch 77/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.4458 - val_loss: 0.4547\n",
      "Epoch 78/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.4568 - val_loss: 0.4548\n",
      "Epoch 79/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4809 - val_loss: 0.4547\n",
      "Epoch 80/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4786 - val_loss: 0.4536\n",
      "Epoch 81/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: 0.4477 - val_loss: 0.4539\n",
      "Epoch 82/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.4869 - val_loss: 0.4523\n",
      "Epoch 83/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.4588 - val_loss: 0.4491\n",
      "Epoch 84/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4904 - val_loss: 0.4491\n",
      "Epoch 85/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.4246 - val_loss: 0.4480\n",
      "Epoch 86/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4561 - val_loss: 0.4514\n",
      "Epoch 87/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4921 - val_loss: 0.4507\n",
      "Epoch 88/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4372 - val_loss: 0.4515\n",
      "Epoch 89/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.4614 - val_loss: 0.4494\n",
      "Epoch 90/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4473 - val_loss: 0.4478\n",
      "Epoch 91/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.4575 - val_loss: 0.4496\n",
      "Epoch 92/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4407 - val_loss: 0.4498\n",
      "Epoch 93/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.4447 - val_loss: 0.4515\n",
      "Epoch 94/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.4402 - val_loss: 0.4523\n",
      "Epoch 95/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.4170 - val_loss: 0.4500\n",
      "Epoch 96/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4588 - val_loss: 0.4467\n",
      "Epoch 97/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4302 - val_loss: 0.4481\n",
      "Epoch 98/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.4819 - val_loss: 0.4472\n",
      "Epoch 99/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4686 - val_loss: 0.4456\n",
      "Epoch 100/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4810 - val_loss: 0.4432\n",
      "Epoch 101/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - loss: 0.4620 - val_loss: 0.4414\n",
      "Epoch 102/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.4678 - val_loss: 0.4403\n",
      "Epoch 103/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.4534 - val_loss: 0.4396\n",
      "Epoch 104/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4425 - val_loss: 0.4391\n",
      "Epoch 105/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.4445 - val_loss: 0.4409\n",
      "Epoch 106/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.4501 - val_loss: 0.4400\n",
      "Epoch 107/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.4399 - val_loss: 0.4413\n",
      "Epoch 108/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.4545 - val_loss: 0.4388\n",
      "Epoch 109/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.4563 - val_loss: 0.4386\n",
      "Epoch 110/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - loss: 0.4310 - val_loss: 0.4380\n",
      "Epoch 111/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.4402 - val_loss: 0.4362\n",
      "Epoch 112/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.4460 - val_loss: 0.4360\n",
      "Epoch 113/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.4560 - val_loss: 0.4361\n",
      "Epoch 114/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4093 - val_loss: 0.4394\n",
      "Epoch 115/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.4292 - val_loss: 0.4409\n",
      "Epoch 116/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 38ms/step - loss: 0.4395 - val_loss: 0.4418\n",
      "Epoch 117/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4553 - val_loss: 0.4404\n",
      "Epoch 118/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.4423 - val_loss: 0.4416\n",
      "Epoch 119/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4464 - val_loss: 0.4402\n",
      "Epoch 120/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4360 - val_loss: 0.4411\n",
      "Epoch 121/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - loss: 0.4526 - val_loss: 0.4421\n",
      "Epoch 122/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4206 - val_loss: 0.4366\n",
      "Epoch 123/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4546 - val_loss: 0.4358\n",
      "Epoch 124/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4339 - val_loss: 0.4375\n",
      "Epoch 125/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.4380 - val_loss: 0.4416\n",
      "Epoch 126/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4513 - val_loss: 0.4413\n",
      "Epoch 127/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4314 - val_loss: 0.4375\n",
      "Epoch 128/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4346 - val_loss: 0.4422\n",
      "Epoch 129/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.4166 - val_loss: 0.4421\n",
      "Epoch 130/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.4859 - val_loss: 0.4413\n",
      "Epoch 131/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.4285 - val_loss: 0.4435\n",
      "Epoch 132/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.4264 - val_loss: 0.4392\n",
      "Epoch 133/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - loss: 0.4350 - val_loss: 0.4372\n",
      "Epoch 134/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - loss: 0.4499 - val_loss: 0.4373\n",
      "Epoch 135/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.4433 - val_loss: 0.4380\n",
      "Epoch 136/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.4203 - val_loss: 0.4352\n",
      "Epoch 137/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.4596 - val_loss: 0.4343\n",
      "Epoch 138/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - loss: 0.4267 - val_loss: 0.4345\n",
      "Epoch 139/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4259 - val_loss: 0.4369\n",
      "Epoch 140/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.4629 - val_loss: 0.4338\n",
      "Epoch 141/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.3964 - val_loss: 0.4334\n",
      "Epoch 142/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.4067 - val_loss: 0.4334\n",
      "Epoch 143/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.4178 - val_loss: 0.4341\n",
      "Epoch 144/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - loss: 0.4048 - val_loss: 0.4367\n",
      "Epoch 145/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.4407 - val_loss: 0.4359\n",
      "Epoch 146/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.4607 - val_loss: 0.4370\n",
      "Epoch 147/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.4561 - val_loss: 0.4361\n",
      "Epoch 148/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - loss: 0.4521 - val_loss: 0.4364\n",
      "Epoch 149/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - loss: 0.4645 - val_loss: 0.4350\n",
      "Epoch 150/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.4359 - val_loss: 0.4345\n",
      "Epoch 151/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - loss: 0.4108 - val_loss: 0.4345\n",
      "Epoch 152/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.4402 - val_loss: 0.4338\n",
      "Epoch 153/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.4642 - val_loss: 0.4338\n",
      "Epoch 154/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.4100 - val_loss: 0.4344\n",
      "Epoch 155/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.4087 - val_loss: 0.4355\n",
      "Epoch 156/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.4224 - val_loss: 0.4331\n",
      "Epoch 157/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.4140 - val_loss: 0.4326\n",
      "Epoch 158/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.4643 - val_loss: 0.4320\n",
      "Epoch 159/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.4309 - val_loss: 0.4323\n",
      "Epoch 160/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.4275 - val_loss: 0.4328\n",
      "Epoch 161/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4227 - val_loss: 0.4311\n",
      "Epoch 162/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.4317 - val_loss: 0.4331\n",
      "Epoch 163/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.4231 - val_loss: 0.4317\n",
      "Epoch 164/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.4066 - val_loss: 0.4314\n",
      "Epoch 165/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.4264 - val_loss: 0.4321\n",
      "Epoch 166/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.3895 - val_loss: 0.4311\n",
      "Epoch 167/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - loss: 0.4065 - val_loss: 0.4301\n",
      "Epoch 168/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.4603 - val_loss: 0.4296\n",
      "Epoch 169/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4430 - val_loss: 0.4306\n",
      "Epoch 170/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.4223 - val_loss: 0.4316\n",
      "Epoch 171/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - loss: 0.4408 - val_loss: 0.4327\n",
      "Epoch 172/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4218 - val_loss: 0.4326\n",
      "Epoch 173/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.4037 - val_loss: 0.4294\n",
      "Epoch 174/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4394 - val_loss: 0.4307\n",
      "Epoch 175/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4239 - val_loss: 0.4297\n",
      "Epoch 176/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4329 - val_loss: 0.4297\n",
      "Epoch 177/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.4226 - val_loss: 0.4280\n",
      "Epoch 178/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.3960 - val_loss: 0.4276\n",
      "Epoch 179/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.4143 - val_loss: 0.4315\n",
      "Epoch 180/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4537 - val_loss: 0.4297\n",
      "Epoch 181/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4296 - val_loss: 0.4288\n",
      "Epoch 182/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4046 - val_loss: 0.4259\n",
      "Epoch 183/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.4145 - val_loss: 0.4294\n",
      "Epoch 184/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.4222 - val_loss: 0.4310\n",
      "Epoch 185/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4270 - val_loss: 0.4301\n",
      "Epoch 186/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.4029 - val_loss: 0.4274\n",
      "Epoch 187/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.4495 - val_loss: 0.4263\n",
      "Epoch 188/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4353 - val_loss: 0.4278\n",
      "Epoch 189/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.4159 - val_loss: 0.4277\n",
      "Epoch 190/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.4351 - val_loss: 0.4261\n",
      "Epoch 191/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.3770 - val_loss: 0.4271\n",
      "Epoch 192/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.4448 - val_loss: 0.4259\n",
      "Epoch 193/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.4379 - val_loss: 0.4263\n",
      "Epoch 194/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.4110 - val_loss: 0.4263\n",
      "Epoch 195/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.4235 - val_loss: 0.4263\n",
      "Epoch 196/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 0.4107 - val_loss: 0.4289\n",
      "Epoch 197/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - loss: 0.4210 - val_loss: 0.4291\n",
      "Epoch 198/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4256 - val_loss: 0.4305\n",
      "Epoch 199/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.4289 - val_loss: 0.4269\n",
      "Epoch 200/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.4362 - val_loss: 0.4240\n",
      "Epoch 201/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4295 - val_loss: 0.4256\n",
      "Epoch 202/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - loss: 0.4264 - val_loss: 0.4247\n",
      "Epoch 203/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.4240 - val_loss: 0.4240\n",
      "Epoch 204/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4474 - val_loss: 0.4240\n",
      "Epoch 205/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4062 - val_loss: 0.4244\n",
      "Epoch 206/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.4037 - val_loss: 0.4260\n",
      "Epoch 207/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - loss: 0.4007 - val_loss: 0.4277\n",
      "Epoch 208/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4125 - val_loss: 0.4234\n",
      "Epoch 209/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.4060 - val_loss: 0.4250\n",
      "Epoch 210/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - loss: 0.3877 - val_loss: 0.4283\n",
      "Epoch 211/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4288 - val_loss: 0.4265\n",
      "Epoch 212/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4107 - val_loss: 0.4281\n",
      "Epoch 213/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - loss: 0.3989 - val_loss: 0.4256\n",
      "Epoch 214/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.3706 - val_loss: 0.4269\n",
      "Epoch 215/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - loss: 0.3925 - val_loss: 0.4266\n",
      "Epoch 216/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - loss: 0.4016 - val_loss: 0.4277\n",
      "Epoch 217/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.4089 - val_loss: 0.4260\n",
      "Epoch 218/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.4151 - val_loss: 0.4289\n",
      "Epoch 219/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - loss: 0.4199 - val_loss: 0.4278\n",
      "Epoch 220/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.3980 - val_loss: 0.4269\n",
      "Epoch 221/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - loss: 0.4192 - val_loss: 0.4261\n",
      "Epoch 222/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.4187 - val_loss: 0.4293\n",
      "Epoch 223/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4203 - val_loss: 0.4274\n",
      "Epoch 224/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - loss: 0.4158 - val_loss: 0.4255\n",
      "Epoch 225/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.3967 - val_loss: 0.4239\n",
      "Epoch 226/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - loss: 0.4292 - val_loss: 0.4227\n",
      "Epoch 227/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.4135 - val_loss: 0.4237\n",
      "Epoch 228/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4091 - val_loss: 0.4253\n",
      "Epoch 229/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 65ms/step - loss: 0.4188 - val_loss: 0.4253\n",
      "Epoch 230/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.4184 - val_loss: 0.4261\n",
      "Epoch 231/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.4252 - val_loss: 0.4273\n",
      "Epoch 232/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.3946 - val_loss: 0.4256\n",
      "Epoch 233/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.3894 - val_loss: 0.4269\n",
      "Epoch 234/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - loss: 0.4015 - val_loss: 0.4274\n",
      "Epoch 235/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - loss: 0.3481 - val_loss: 0.4292\n",
      "Epoch 236/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - loss: 0.4200 - val_loss: 0.4288\n",
      "Epoch 237/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - loss: 0.4035 - val_loss: 0.4242\n",
      "Epoch 238/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - loss: 0.3832 - val_loss: 0.4281\n",
      "Epoch 239/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - loss: 0.4127 - val_loss: 0.4289\n",
      "Epoch 240/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - loss: 0.4254 - val_loss: 0.4290\n",
      "Epoch 241/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - loss: 0.3872 - val_loss: 0.4268\n",
      "Epoch 242/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - loss: 0.4472 - val_loss: 0.4233\n",
      "Epoch 243/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.3977 - val_loss: 0.4253\n",
      "Epoch 244/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: 0.4055 - val_loss: 0.4275\n",
      "Epoch 245/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.3993 - val_loss: 0.4268\n",
      "Epoch 246/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - loss: 0.3898 - val_loss: 0.4229\n",
      "Epoch 247/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 64ms/step - loss: 0.4004 - val_loss: 0.4226\n",
      "Epoch 248/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.4140 - val_loss: 0.4223\n",
      "Epoch 249/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - loss: 0.4158 - val_loss: 0.4226\n",
      "Epoch 250/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - loss: 0.4088 - val_loss: 0.4226\n",
      "Epoch 251/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.4325 - val_loss: 0.4227\n",
      "Epoch 252/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.4134 - val_loss: 0.4221\n",
      "Epoch 253/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - loss: 0.4228 - val_loss: 0.4259\n",
      "Epoch 254/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - loss: 0.3764 - val_loss: 0.4278\n",
      "Epoch 255/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - loss: 0.4094 - val_loss: 0.4292\n",
      "Epoch 256/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4190 - val_loss: 0.4295\n",
      "Epoch 257/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - loss: 0.4288 - val_loss: 0.4296\n",
      "Epoch 258/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.4128 - val_loss: 0.4282\n",
      "Epoch 259/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - loss: 0.3720 - val_loss: 0.4247\n",
      "Epoch 260/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - loss: 0.4170 - val_loss: 0.4234\n",
      "Epoch 261/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.4383 - val_loss: 0.4222\n",
      "Epoch 262/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.3883 - val_loss: 0.4232\n",
      "Epoch 263/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.3881 - val_loss: 0.4214\n",
      "Epoch 264/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.4002 - val_loss: 0.4264\n",
      "Epoch 265/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - loss: 0.3791 - val_loss: 0.4267\n",
      "Epoch 266/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.3926 - val_loss: 0.4233\n",
      "Epoch 267/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4100 - val_loss: 0.4218\n",
      "Epoch 268/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - loss: 0.4339 - val_loss: 0.4239\n",
      "Epoch 269/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 0.4271 - val_loss: 0.4263\n",
      "Epoch 270/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - loss: 0.4343 - val_loss: 0.4245\n",
      "Epoch 271/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: 0.3912 - val_loss: 0.4228\n",
      "Epoch 272/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.3914 - val_loss: 0.4242\n",
      "Epoch 273/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - loss: 0.3928 - val_loss: 0.4279\n",
      "Epoch 274/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - loss: 0.3980 - val_loss: 0.4265\n",
      "Epoch 275/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - loss: 0.4043 - val_loss: 0.4243\n",
      "Epoch 276/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - loss: 0.4015 - val_loss: 0.4266\n",
      "Epoch 277/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.3962 - val_loss: 0.4271\n",
      "Epoch 278/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - loss: 0.4064 - val_loss: 0.4255\n",
      "Epoch 279/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - loss: 0.4113 - val_loss: 0.4242\n",
      "Epoch 280/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - loss: 0.4007 - val_loss: 0.4239\n",
      "Epoch 281/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: 0.3693 - val_loss: 0.4258\n",
      "Epoch 282/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.4126 - val_loss: 0.4250\n",
      "Epoch 283/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - loss: 0.3838 - val_loss: 0.4267\n",
      "Epoch 284/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: 0.3871 - val_loss: 0.4271\n",
      "Epoch 285/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - loss: 0.3966 - val_loss: 0.4257\n",
      "Epoch 286/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - loss: 0.4017 - val_loss: 0.4239\n",
      "Epoch 287/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - loss: 0.3874 - val_loss: 0.4251\n",
      "Epoch 288/3000\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - loss: 0.3898 - val_loss: 0.4279\n",
      "Epoch 288: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x282a57c43e0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=3000,\n",
    "          validation_data=(x_test, y_test), verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6ff4a310-5b71-4a91-8eef-b6c52b888793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss = pd.DataFrame(model.history.history)\n",
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "29fa6eaf-de29-4bf6-a41a-32719540af20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.94      0.85       105\n",
      "           1       0.88      0.61      0.72        74\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.83      0.78      0.78       179\n",
      "weighted avg       0.82      0.80      0.80       179\n",
      "\n",
      "[[99  6]\n",
      " [29 45]]\n"
     ]
    }
   ],
   "source": [
    "predictions = (model.predict(x_test) > 0.5)*1\n",
    "print(predictions)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "db8aeef0-3ed0-400b-b773-c63b8578b779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Predicted0  Predicted1\n",
      "Actual0          99           6\n",
      "Actual1          29          45\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "cm_df = pd.DataFrame(confusion_matrix(y_test,predictions))\n",
    "cm_df.columns = ['Predicted0','Predicted1']\n",
    "cm_df = cm_df.rename(index={0: 'Actual0',1:'Actual1'})\n",
    "print(cm_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "090b733f-3baa-4c31-97d7-0770aeb3ec79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8044692737430168"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cm = np.array(cm_df)\n",
    "accuracy_train = (cm[0,0]+cm[1,1])/cm.sum()\n",
    "accuracy_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec27225-294f-488b-bfc6-fa4fb0aee474",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
